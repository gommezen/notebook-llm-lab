{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9716c516-ea0f-4fcf-b026-39bc95ff62ae",
   "metadata": {},
   "source": [
    "# Noter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36029c06",
   "metadata": {},
   "source": [
    "In the following you import the function `ask_model` that uses an LLM with an instruction that you provide as a string and displays the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86a053-0fc1-4c1e-ac04-ab78e1854cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters and words\n",
    "# len(answer)\n",
    "# len(answer.split())\n",
    "\n",
    "\n",
    "# Does the answer contain certain keywords?\n",
    "# \"variance\" in answer\n",
    "# \"neural network\" in answer.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Count how many times a word appears\n",
    "\n",
    "#answer.lower().count(\"data\")\n",
    "\n",
    "\n",
    "# answers = [\n",
    "#     ask_model(\"Explain quantization.\"),\n",
    "#     ask_model(\"Explain pruning.\"),\n",
    "#     ask_model(\"Explain distillation.\")\n",
    "# ]\n",
    "\n",
    "# # Compare length of explanations\n",
    "# lengths = [len(a.split()) for a in answers]\n",
    "# print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b83500-fbed-4859-83e9-6d252781748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Move one level up from the notebooks folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Add /src to the Python path if not already there\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from llm_utils.llm_client import ask_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3cf0da-5d25-4d3f-8268-15da9fcd8e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization is a technique used to reduce the size of machine learning models, including Large Language Models (LLMs), without significantly impacting their performance. In essence, it involves converting the continuous range values representing model parameters into fixed-point integers with fewer bits than floating-point numbers typically use. This not only results in a smaller memory footprint but also speeds up inference and can be beneficial for deploying models on resource-constrained devices like mobile phones or IoT gadgets, which may have limited computational power compared to high-end servers where LLMs are often trained and run as originally. Quantization helps in making the deployment of these powerful language processing tools more accessible across a broader range of platforms by reducing their size while attempting to maintain effectiveness at natural language understanding tasks such as translation, summarization or question answering within reasonable computational budgets.\n"
     ]
    }
   ],
   "source": [
    "# Basic usage\n",
    "answer = ask_model(\"Summarize what quantization does in LLMs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a453f34-755f-41ba-9660-cceb5615d51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)\n",
    "\"models\" in answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a26379-f8d1-421e-97f5-4689d6e6bcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization compresses LLMs for faster and smaller performance with minimal accuracy loss on low-power devices like phones or IoT gadgets without compromising the quality of language processing tasks. It simplifies complex models to fixed-point integers, making them deployable in various environments where computational resources are limited.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quantization compresses LLMs for faster and smaller performance with minimal accuracy loss on low-power devices like phones or IoT gadgets without compromising the quality of language processing tasks. It simplifies complex models to fixed-point integers, making them deployable in various environments where computational resources are limited.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_model(f\"Make this answer simpler and shorter: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba7839-01bb-4586-bb3d-f40a468f586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters and words\n",
    "len(answer)\n",
    "len(answer.split())\n",
    "\n",
    "# Does the answer contain certain keywords?\n",
    "\"variance\" in answer\n",
    "\"neural network\" in answer.lower()\n",
    "\n",
    "# Count how many times a word appears\n",
    "answer.lower().count(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f95775-d0c4-4e6c-870f-e62dc1a175ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(answer)\n",
    "print(\"Sentiment:\", blob.sentiment)\n",
    "print(\"Nouns:\", blob.noun_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f5e53-edfa-458f-94cb-79eea250661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [\n",
    "    ask_model(\"Explain quantization.\"),\n",
    "    ask_model(\"Explain pruning.\"),\n",
    "    ask_model(\"Explain distillation.\")\n",
    "]\n",
    "\n",
    "# Compare length of explanations\n",
    "lengths = [len(a.split()) for a in answers]\n",
    "print(lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e164d69",
   "metadata": {},
   "source": [
    "ask_model(f\"What are the three main ideas in this text? {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cefb92-113c-481b-a674-96d5b5603bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/results/quantization_summary.txt\", \"w\") as f:\n",
    "    f.write(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
