{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ðŸ“˜ Notebook: 02_data_cleaning_and_summary.ipynb\n",
    "#\n",
    "# Purpose:\n",
    "#   Prepare a clean, high-quality summary dataset of all running sessions.\n",
    "#   This notebook filters out non-running or corrupted data, aggregates\n",
    "#   individual GPS records into one-row-per-run summaries, and enriches them\n",
    "#   with temporal and quality information.\n",
    "#\n",
    "# Context:\n",
    "#   - Follows Stage 1 (EDA & Data Quality Audit)\n",
    "#   - Produces a ready-to-ingest dataset for Neo4j and ML analysis\n",
    "#\n",
    "# Main steps:\n",
    "#   1. Load raw processed data (strava_runs.parquet)\n",
    "#   2. Apply cleaning and filtering rules based on the data quality manifest\n",
    "#   3. Aggregate per run (distance, pace, cadence, heart rate, elevation)\n",
    "#   4. Add date/time and quality metrics\n",
    "#   5. Save the final summary to:\n",
    "#        data/strava/processed/run_summary_cleaned.{csv,parquet}\n",
    "#\n",
    "# Input:\n",
    "#   data/strava/processed/strava_runs.parquet\n",
    "#   data/strava/processed/data_quality_manifest.csv\n",
    "#\n",
    "# Output:\n",
    "#   data/strava/processed/run_summary_cleaned.parquet\n",
    "#   data/strava/processed/run_summary_cleaned.csv\n",
    "#\n",
    "# Next step:\n",
    "#   Stage 3 â†’ Neo4j graph ingestion and visualization\n",
    "# -----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Stage 2: Cleaning & Per-Run Summary ---------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "raw_path = Path(\"../data/strava/processed/strava_runs.parquet\")\n",
    "df = pd.read_parquet(raw_path)\n",
    "print(f\"Loaded {len(df):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.0 Create or refresh data quality manifest --------------------------\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "processed_dir = Path(\"data/strava/processed\")\n",
    "manifest_path = processed_dir / \"data_quality_manifest.csv\"\n",
    "\n",
    "# Whether to force regeneration\n",
    "force_recreate_manifest = True\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def classify_column(col: str, missing_pct: float, nunique: int) -> str:\n",
    "    \"\"\"Heuristic classification of columns.\"\"\"\n",
    "    col_lower = col.lower()\n",
    "    if col_lower.startswith(\"unknown\") or \"unnamed\" in col_lower:\n",
    "        return \"drop\"\n",
    "    if missing_pct > 70:\n",
    "        return \"review\"\n",
    "    if missing_pct > 50:\n",
    "        return \"optional\"\n",
    "    if nunique <= 1:\n",
    "        return \"drop\"  # constant or empty\n",
    "    if col_lower in [\n",
    "        \"distance\", \"distance_km\", \"pace_min_per_km\", \"timestamp\",\n",
    "        \"speed\", \"cadence\", \"altitude\", \"heart_rate\", \"run_id\",\n",
    "        \"lat\", \"lon\", \"position_lat\", \"position_long\",\n",
    "    ]:\n",
    "        return \"core\"\n",
    "    return \"optional\"\n",
    "\n",
    "if not manifest_path.exists() or force_recreate_manifest:\n",
    "    print(\"ðŸ”„ Creating or refreshing data quality manifest...\")\n",
    "\n",
    "    # Compute stats\n",
    "    stats = pd.DataFrame({\n",
    "        \"column\": df.columns,\n",
    "        \"dtype\": [str(df[c].dtype) for c in df.columns],\n",
    "        \"non_null_count\": df.notna().sum().values,\n",
    "        \"missing_pct\": (df.isna().mean().values * 100).round(1),\n",
    "        \"nunique\": df.nunique().values,\n",
    "    })\n",
    "\n",
    "    stats[\"category\"] = [\n",
    "        classify_column(c, m, n)\n",
    "        for c, m, n in zip(stats[\"column\"], stats[\"missing_pct\"], stats[\"nunique\"])\n",
    "    ]\n",
    "\n",
    "    stats = stats.sort_values([\"category\", \"missing_pct\"], ascending=[True, False])\n",
    "\n",
    "    stats.to_csv(manifest_path, index=False)\n",
    "    print(f\"âœ… Manifest refreshed with {len(stats)} columns at: {manifest_path.resolve()}\")\n",
    "    print(stats[\"category\"].value_counts().to_string())\n",
    "else:\n",
    "    print(f\"âœ… Manifest already exists and not overwritten: {manifest_path.resolve()}\")\n",
    "\n",
    "# Preview top of manifest\n",
    "pd.read_csv(manifest_path).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 Drop unknown or low-quality columns ------------------------------\n",
    "manifest = pd.read_csv(\"../data/strava/processed/data_quality_manifest.csv\", index_col=\"column\")\n",
    "keep_cols = manifest.query(\"category != 'drop'\").index.tolist()\n",
    "df = df[keep_cols]\n",
    "print(f\"Keeping {len(keep_cols)} columns based on manifest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.2 Apply activity-level filters ------------------------------------\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"distance_km\", \"pace_min_per_km\"])\n",
    "df = df[df[\"distance_km\"] >= 0.5]\n",
    "df = df[(df[\"pace_min_per_km\"] >= 2) & (df[\"pace_min_per_km\"] <= 15)]\n",
    "df = df[~((df[\"cadence\"] == 0) & (df[\"speed\"] == 0))]\n",
    "print(f\"Removed {before - len(df):,} noisy rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.3 Aggregate per-run summary (robust to missing HR) ----------------\n",
    "agg_spec = dict(\n",
    "    records=(\"timestamp\", \"count\"),\n",
    "    start_time=(\"timestamp\", \"min\"),\n",
    "    end_time=(\"timestamp\", \"max\"),\n",
    "    total_distance_km=(\"distance_km\", \"max\"),\n",
    "    avg_pace=(\"pace_min_per_km\", \"mean\"),\n",
    "    avg_speed=(\"speed\", \"mean\"),\n",
    "    avg_cadence=(\"cadence\", \"mean\"),\n",
    "    elevation_gain=(\"altitude\", lambda s: s.max() - s.min()),\n",
    ")\n",
    "\n",
    "if \"heart_rate\" in df.columns:\n",
    "    agg_spec[\"avg_hr\"] = (\"heart_rate\", \"mean\")\n",
    "\n",
    "summary = df.groupby(\"run_id\").agg(**agg_spec).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.4 Add date context -------------------------------------------------\n",
    "summary[\"date\"] = pd.to_datetime(summary[\"start_time\"]).dt.date\n",
    "summary[\"weekday\"] = pd.to_datetime(summary[\"start_time\"]).dt.day_name()\n",
    "summary[\"month\"] = pd.to_datetime(summary[\"start_time\"]).dt.to_period(\"M\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.5 Run-level quality metrics ---------------------------------------\n",
    "\n",
    "# per-run % missing values\n",
    "missing_pct = (\n",
    "    df.isna()\n",
    "      .groupby(df[\"run_id\"])\n",
    "      .mean()\n",
    "      .mean(axis=1) * 100\n",
    ")\n",
    "summary = summary.merge(missing_pct.rename(\"missing_pct\"), on=\"run_id\", how=\"left\")\n",
    "\n",
    "# per-run duration in minutes\n",
    "summary[\"duration_min\"] = (\n",
    "    (pd.to_datetime(summary[\"end_time\"]) - pd.to_datetime(summary[\"start_time\"]))\n",
    "    .dt.total_seconds() / 60\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.6 Save results -----------------------------------------------------\n",
    "out_path = Path(\"../data/strava/processed/run_summary_cleaned.parquet\")\n",
    "summary.to_parquet(out_path, index=False)\n",
    "summary.to_csv(out_path.with_suffix(\".csv\"), index=False)\n",
    "print(f\"âœ… Saved {len(summary):,} clean runs â†’ {out_path}\")\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-llm-lab",
   "language": "python",
   "name": "notebook-llm-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
